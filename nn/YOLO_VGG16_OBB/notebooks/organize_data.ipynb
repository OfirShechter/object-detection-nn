{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd Rar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd object-detection-nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cd ../../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_mode = True\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from nn.YOLO_VGG16_OBB.utils.constants import ANCHORS\n",
    "from nn.YOLO_VGG16_OBB.prepare_data.dota_dataset_memory import DotaDataset\n",
    "from nn.YOLO_VGG16_OBB.prepare_data.transforms import train_transform, test_transform\n",
    "from nn.YOLO_VGG16_OBB.utils.helpers import convert_cells_to_bboxes, load_checkpoint, nms, plot_image, save_checkpoint\n",
    "from nn.YOLO_VGG16_OBB.utils.constants import device, s, leanring_rate, save_model, checkpoint_file\n",
    "from nn.YOLO_VGG16_OBB.model.YOLO_VGG16_OBB import YOLO_VGG16_OBB\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from nn.YOLO_VGG16_OBB.model.loss import YOLOLoss\n",
    "from tqdm import tqdm\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.transforms as T\n",
    "\n",
    "if remote_mode:\n",
    "    model_path_base = f\"/home/dcor/niskhizov/Rar/object-detection-nn/nn/YOLO_VGG16_OBB/notebooks/vgg_f_obb_v2_model\"\n",
    "else:\n",
    "    model_path_base = f\"nn/YOLO_VGG16_OBB/notebooks/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['plane','ship', 'storage-tank', 'baseball-diamond', 'tennis-court', 'basketball-court', 'ground-track-field', 'harbor', 'bridge', 'large-vehicle', 'small-vehicle', 'helicopter', 'roundabout', 'soccer-ball-field', 'swimming-pool']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model from YOLOv3 class \n",
    "load_model = True\n",
    "save_model = False\n",
    "model = YOLO_VGG16_OBB(num_classes=len(categories)).to(device) \n",
    "\n",
    "# Defining the optimizer \n",
    "optimizer = optim.Adam(model.parameters(), lr = leanring_rate) \n",
    "\n",
    "# Defining the loss function \n",
    "loss_fn = YOLOLoss() \n",
    "\n",
    "# Defining the scaler for mixed precision training \n",
    "scaler = torch.amp.GradScaler(device=device) \n",
    "# Loading the checkpoint \n",
    "if load_model: \n",
    "    load_checkpoint(model_path_base + f\"e297_vgg16_{checkpoint_file}\", model, optimizer, leanring_rate, device) \n",
    "\n",
    "# Initialize TensorBoard writer\n",
    "# writer = SummaryWriter(log_dir='runs/YOLO_VGG16_OBB_v2')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DotaDataset( \n",
    "\tcategories=categories,\n",
    "\tgrid_sizes=[13, 26, 52], \n",
    "\tanchors=ANCHORS, \n",
    "\ttransform=train_transform \n",
    ") \n",
    "\n",
    "# Defining the train data loader \n",
    "train_loader = torch.utils.data.DataLoader( \n",
    "\tdataset=dataset, \n",
    "\tbatch_size=8, \n",
    "\tshuffle=True, \n",
    "\tnum_workers=2,\n",
    " \tprefetch_factor=10,\n",
    ") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = DotaDataset(\n",
    "    categories=categories,\n",
    "    grid_sizes=[13, 26, 52],\n",
    "    anchors=ANCHORS,\n",
    "    transform=test_transform,  # Use the same transform for validation\n",
    "    data_base_path = f\"nn/dotadataset/train\"\n",
    ")\n",
    "\n",
    "# Create the validation data loader\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "val_loader_iter = iter(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the anchors \n",
    "scaled_anchors = ( \n",
    "\ttorch.tensor(ANCHORS) *\n",
    "\ttorch.tensor(s).unsqueeze(1).unsqueeze(1).repeat(1,3,2) \n",
    ").to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Getting a sample image from the test data loader \n",
    "try:\n",
    "\tx, y = next(val_loader_iter)\n",
    "except StopIteration:\n",
    "\tval_loader_iter = iter(val_loader)\n",
    "\tx, y = next(val_loader_iter)\n",
    "x = x.to(device) \n",
    "\n",
    "print(\"###################################### display and report image ######################################\")\n",
    "with torch.no_grad():\n",
    "\tscaled_anchors = ( \n",
    "\ttorch.tensor(ANCHORS) *\n",
    "\ttorch.tensor(s).unsqueeze(1).unsqueeze(1).repeat(1,3,2) \n",
    "\t).to(device) \n",
    "\toutput = model(x)\n",
    "\ty0, y1, y2 = ( \n",
    "\t\ty[0].to(device), \n",
    "\t\ty[1].to(device), \n",
    "\t\ty[2].to(device), \n",
    "\t) \n",
    "\n",
    "\twith torch.amp.autocast(device_type=device): \n",
    "\t\t# # Getting the model predictions \n",
    "\t\t# outputs = model(x) \n",
    "\t\t# Calculating the loss at each scale \n",
    "\t\tloss = ( \n",
    "\t\t\tloss_fn(output[0], y0, scaled_anchors[0]) \n",
    "\t\t\t+ loss_fn(output[1], y1, scaled_anchors[1]) \n",
    "\t\t\t+ loss_fn(output[2], y2, scaled_anchors[2]) \n",
    "\t\t) \n",
    "\n",
    "\t# TEMP- print target boxes\n",
    "\tbboxes = [[] for _ in range(x.shape[0])]\n",
    "\tfor i in range(3):\n",
    "\t\tbatch_size, A, S, _, _ = y[i].shape\n",
    "\t\tanchor = scaled_anchors[i]\n",
    "\t\tboxes_scale_i = convert_cells_to_bboxes(y[i], anchor, s=S, is_predictions=False)\n",
    "\t\tfor idx, box in enumerate(boxes_scale_i):\n",
    "\t\t\tbboxes[idx] += box\n",
    "\n",
    "\ti = 0\n",
    "\tprint('bboxes[i] shape:', np.array(bboxes[i]).shape)\n",
    "\tnms_boxes = nms(bboxes[i], iou_threshold=0.6, threshold=0.4)\n",
    "\timg_with_boxes = plot_image(x[i].permute(1, 2, 0).detach().cpu(), nms_boxes, categories)\n",
    "\timg_with_boxes = T.ToTensor()(img_with_boxes)\n",
    "\n",
    "\t# # Print predictions\n",
    "\t# writer.add_scalar('Loss/val', loss.item(), e * len(train_loader) + batch_idx)\n",
    "\n",
    "\tbboxes = [[] for _ in range(x.shape[0])]\n",
    "\tfor i in range(3):\n",
    "\t\tbatch_size, A, S, _, _ = output[i].shape\n",
    "\t\tanchor = scaled_anchors[i]\n",
    "\t\tboxes_scale_i = convert_cells_to_bboxes(output[i], anchor, s=S, is_predictions=True)\n",
    "\t\tfor idx, box in enumerate(boxes_scale_i):\n",
    "\t\t\tbboxes[idx] += box\n",
    "\n",
    "\ti = 0\n",
    "\tprint('bboxes[i] shape:', np.array(bboxes[i]).shape)\n",
    "\tnms_boxes = nms(bboxes[i], iou_threshold=1, threshold=0.1)\n",
    "\timg_with_boxes = plot_image(x[i].permute(1, 2, 0).detach().cpu(), nms_boxes, categories)\n",
    "\timg_with_boxes = T.ToTensor()(img_with_boxes)\n",
    "\t# writer.add_image(f'Val/Image_{e}_{i}_{batch_idx}_before', img_with_boxes, e * len(train_loader) + batch_idx)\n",
    "\n",
    "# model.train()\n",
    "# except Exception as error:\n",
    "# \tprint(error)\n",
    "# \terror_counter += 1\n",
    "# \tif error_counter > 10:\n",
    "# \t\traise error\n",
    "\n",
    "\n",
    "#################\n",
    "# training_loop(train_loader, model, optimizer, loss_fn, scaler, scaled_anchors) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = output[1]\n",
    "target = y1 \n",
    "anchors = scaled_anchors[1]\n",
    "pred_angle = torch.tanh(pred[..., 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[..., 1:3].shape, pred[..., 3:5].shape, pred_angle.unsqueeze(-1).shape, anchors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.exp(pred[..., 3:5]) * anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "obj_d",
   "language": "python",
   "name": "obj_d"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
